{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb01e014-9315-4d41-9c92-9b880c33ade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86e94d00-d4e1-42a3-bd3a-1d4fdaaf9994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-ant-\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e403c356-ac8d-472b-ad8f-0e38af496cf1",
   "metadata": {},
   "source": [
    "### Open AI - GPT Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9dbe911-c5f6-4403-951e-b9e273c53409",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f8a82ae-539f-4e40-a5f8-f760fa4bd9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"Youre are assitant that give answers for a given question\"\n",
    "\n",
    "def user_prompt(question):\n",
    "    question = str(question)\n",
    "    user_prompt = f\"Please give an comprehensive answer for this question: {question}\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5029b69-3c92-4e39-8ddb-c529a4f7e3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_bot_read_GPT():\n",
    "    question = input(\"Add your question here: \")\n",
    "    completion = openai.chat.completions.create(\n",
    "        model = 'gpt-4.1-mini',\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": user_prompt(question)}\n",
    "        ],\n",
    "        temperature=0.7 # values vary from 0 to 1. if we set this to 1, it will give us the most creative idea\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3202a21c-f537-4dc3-84f9-c42e44dd12fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_summary_GPT():\n",
    "    summary = chat_bot_read_GPT()\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9167f1d-8f19-41ed-a516-0edb42940656",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Add your question here:  why LLM models have introduced\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Large Language Models (LLMs) have been introduced to address several key challenges and opportunities in natural language processing (NLP) and artificial intelligence (AI). Their development marks a significant advancement in how machines understand, generate, and interact with human language. Here is a comprehensive explanation of why LLMs have been introduced:\n",
       "\n",
       "1. **Handling the Complexity of Human Language**  \n",
       "Human language is inherently complex, ambiguous, and context-dependent. Traditional rule-based or smaller statistical models struggled to capture the nuances, idiomatic expressions, and diverse syntactic structures found in natural language. LLMs, trained on vast amounts of text data, learn rich representations of language that enable them to understand context, disambiguate meaning, and generate coherent responses.\n",
       "\n",
       "2. **Scaling Up Learning from Data**  \n",
       "Before LLMs, NLP models were often limited by their size and the amount of data they could effectively learn from. The introduction of LLMs leveraged advances in computing power (such as GPUs and TPUs), improved training algorithms, and massive datasets scraped from the internet. This scaling allowed models to learn patterns, facts, and language usage from an unprecedented breadth and depth of text, improving performance across diverse language tasks.\n",
       "\n",
       "3. **Generalization Across Tasks**  \n",
       "Traditional NLP models were typically designed for specific tasks (e.g., sentiment analysis, translation, summarization). LLMs, especially those based on transformer architectures, have demonstrated remarkable ability to generalize across multiple tasks without task-specific training. By using prompt-based learning or fine-tuning, LLMs can adapt to a wide variety of applications, reducing the need to build separate models for each task.\n",
       "\n",
       "4. **Enabling Conversational AI and Human-like Interaction**  \n",
       "One of the driving motivations for LLMs is to create AI systems that can engage in natural, human-like conversations. Applications in customer service, virtual assistants, tutoring, and creative writing benefit greatly from models that understand context, maintain coherence over long dialogues, and generate relevant, informative, and contextually appropriate responses.\n",
       "\n",
       "5. **Facilitating Knowledge Retrieval and Reasoning**  \n",
       "LLMs encode a vast amount of implicit knowledge learned during training, enabling them to answer questions, summarize information, and perform reasoning tasks. This capability supports use cases in education, research, and decision-making, where quick access to synthesized information is valuable.\n",
       "\n",
       "6. **Reducing the Barrier to NLP Deployment**  \n",
       "By providing a powerful, general-purpose language understanding and generation tool, LLMs reduce the technical barrier for developers and organizations to incorporate sophisticated language capabilities into their products and services. This democratization accelerates innovation and broadens the impact of AI technologies.\n",
       "\n",
       "7. **Advancing AI Research and Understanding**  \n",
       "LLMs serve as research platforms to explore fundamental questions about language, cognition, and intelligence. Their success challenges previous assumptions and inspires new models and methods in AI, driving the field forward.\n",
       "\n",
       "**In summary,** LLMs have been introduced to better capture the complexity of human language, leverage large-scale data and computation, generalize across multiple tasks, enable more natural interactions, and democratize access to advanced language technologies. They represent a pivotal step in the evolution of AI systems capable of understanding and generating human language at a high level."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary_GPT()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3d2e58-81d3-40a0-a7c3-8ed8316a66b8",
   "metadata": {},
   "source": [
    "### Anthropic API - Claude Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1eb986f-74c0-4f0d-a7e9-a898cee1a5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "005d0fe9-196a-487a-8b55-b222d4d2eade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_bot_read_Claude():\n",
    "    question = input(\"Add your question here: \")\n",
    "    message = claude.messages.create(\n",
    "        model=\"claude-sonnet-4-20250514\",\n",
    "        max_tokens=200,\n",
    "        temperature=0.7,\n",
    "        system=system_message,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": user_prompt(question)},\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68c2df31-e51d-414c-9880-6e52f62068df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_summary_Claude():\n",
    "    summary = chat_bot_read_Claude()\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0479d2b5-0d19-4245-9584-e4c0e5caf23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Add your question here:  why LLM models have introduced\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Why Large Language Models (LLMs) Were Introduced\n",
       "\n",
       "Large Language Models emerged as a solution to multiple longstanding challenges in artificial intelligence and natural language processing. Here's a comprehensive look at the key reasons for their development:\n",
       "\n",
       "### **1. Limitations of Previous NLP Approaches**\n",
       "\n",
       "**Traditional Methods:**\n",
       "- Earlier NLP systems relied on hand-crafted rules and feature engineering\n",
       "- Required extensive domain expertise and manual programming for each task\n",
       "- Limited ability to handle language complexity and ambiguity\n",
       "- Poor generalization across different domains or languages\n",
       "\n",
       "**Statistical Models:**\n",
       "- While better than rule-based systems, they still required task-specific architectures\n",
       "- Limited context understanding\n",
       "- Struggled with long-range dependencies in text\n",
       "\n",
       "### **2. The Need for General-Purpose Language Understanding**\n",
       "\n",
       "**Versatility Requirements:**\n",
       "- Demand for models that could handle multiple tasks without task-specific training\n",
       "- Need for systems that could adapt"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary_Claude()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce95af8f-268e-4622-8723-5de31e2f4ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0472ed29-4cc7-4f99-9157-373d9fc0d1ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
