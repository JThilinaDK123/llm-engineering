{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc9560ad-5ec7-4a50-bf24-c4d74b9482f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c30f6042-bb16-44be-893c-feda7c6de9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4o-mini\"\n",
    "db_name = \"vector_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b509f05b-791e-4d63-9ac0-4195105e5377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e74f41-9563-427e-b5c1-9e39d1c791ed",
   "metadata": {},
   "source": [
    "#### Read in documents using LangChain's loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "014d13e7-069c-4c77-9f35-a67c0b6ceff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = glob.glob(\"heathprocact_docs/*\")\n",
    "text_loader_kwargs = {'encoding': 'utf-8'}\n",
    "\n",
    "documents = []\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "    loader = DirectoryLoader(folder, glob=\"**/*.md\", loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\n",
    "    folder_docs = loader.load()\n",
    "    for doc in folder_docs:\n",
    "        doc.metadata[\"doc_type\"] = doc_type\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e06df7b0-5f33-487a-8a65-43cae70acedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "584bbdbc-4fa7-4073-adb9-dee6ebf1adf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8756d41-d5ea-4743-a807-27d9dd996eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document types found: vendors, contact, ESG, about, product\n"
     ]
    }
   ],
   "source": [
    "doc_types = set(chunk.metadata['doc_type'] for chunk in chunks)\n",
    "print(f\"Document types found: {', '.join(doc_types)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b6ae42e-2031-48ac-b2d7-0123866b6e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea5e13f-8411-4ee1-b97c-da973684c4a1",
   "metadata": {},
   "source": [
    "### Create vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8a390c5-20a4-4710-b8b4-4e2fe8234b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 vectors with 1,536 dimensions in the vector store\n"
     ]
    }
   ],
   "source": [
    "vectorstore = FAISS.from_documents(chunks, embedding=embeddings)\n",
    "\n",
    "total_vectors = vectorstore.index.ntotal\n",
    "dimensions = vectorstore.index.d\n",
    "\n",
    "print(f\"There are {total_vectors} vectors with {dimensions:,} dimensions in the vector store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b62d8a-d64b-401d-b2de-2b2dee816383",
   "metadata": {},
   "source": [
    "### Chat Application (RAG pipeline with LangChain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7ac7f78-fa7d-4083-a806-881657eb0d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/27/gbz_5drj4l13l6x8mnk54j1w0000gn/T/ipykernel_3563/101531323.py:6: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "## create a new Chat with OpenAI (model)\n",
    "llm = ChatOpenAI(temperature = 0.7, \n",
    "                 model_name = MODEL)\n",
    "\n",
    "## set up the conversation memory for the chat (Memory)\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key = 'chat_history', \n",
    "    return_messages = True)\n",
    "\n",
    "## the retriever is an abstraction over the VectorStore that will be used during RAG (Retreiver)\n",
    "retriever = vectorstore.as_retriever()\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm = llm, \n",
    "    retriever = retriever, \n",
    "    memory = memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "547ea699-b144-44e4-b502-c8214e10f578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heathprocact is a cutting-edge company that specializes in geospatial data, AI, and machine learning models. It focuses on developing AI agents and ESG indicators related to geospatial data, enabling businesses and organizations to make smarter and more sustainable decisions. The company's mission is to bridge technology and sustainability through geospatial intelligence, empowering governments, NGOs, and businesses to address challenges in climate change, natural disasters, and sustainable development.\n"
     ]
    }
   ],
   "source": [
    "query = \"Can you describe Heathprocact in a few sentences\"\n",
    "result = conversation_chain.invoke({\"question\":query})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14c73822-b109-48e6-be8a-cccb1a423744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    result = conversation_chain.invoke({\"question\": message})\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca68987f-e89e-445d-8d1b-2c59003e2ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view = gr.ChatInterface(chat, type=\"messages\").launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34899a2-e925-49c0-b9ec-5a91982d4e05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
